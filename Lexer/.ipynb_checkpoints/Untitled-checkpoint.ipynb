{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file imports\n",
    "path_tokens = 'tokens.txt'\n",
    "path_reserved = 'reserved.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved set\n",
    "f = open('reserved.txt')\n",
    "reserved_set = set([x.strip() for x in f.readlines()])\n",
    "f.close()\n",
    "\n",
    "#Generate all regex we will need\n",
    "\n",
    "# Util\n",
    "regex = {\n",
    "    'id' : '[_a-zA-Z_]*[A-Za-z0-9]+[_A-Za-z0-9_]*',\n",
    "    'string': r'([\"])(?:(?=(\\\\?))\\2.)*?\\1',\n",
    "    'numerico' : '[+-]?[0-9]+(?:\\.[0-9]+)?(?:[eE][+-][0-9]+)?',\n",
    "    'comment' : '#'\n",
    "}\n",
    "# Token Regex - Awuful\n",
    "f = open('tokens.txt','r')\n",
    "token_array = [x.strip().split('\\t') for x in f.readlines()]\n",
    "tokens = [x[0] for x in  token_array]\n",
    "f.close()\n",
    "\n",
    "token_set = {k:v for k,v in token_array}\n",
    "\n",
    "token_regex = r''.join('(?:'+re.escape(y)+')|' for y in [x[0] for x in  token_array])[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?:\\\\()|(?:\\\\))|(?:\\\\+\\\\+)|(?:\\\\-\\\\-)|(?:\\\\^)|(?:not)|(?:\\\\~)|(?:\\\\+)|(?:\\\\-)|(?:@)|(?:\\\\?)|(?:\\\\*\\\\*)|(?:\\\\*)|(?:/)|(?:%)|(?::=:)|(?:\\\\|\\\\|)|(?:<<)|(?:>>)|(?:=)|(?:!)|(?:;)|(?::=)|(?::)|(?:;)|(?:,)|(?:\\\\.)|(?:\\\\->)|(?:\\\\+:=)|(?:\\\\-:=)|(?:\\\\*:=)|(?:/:=)|(?:%:=)|(?:\\\\*\\\\*:=)|(?:\\\\|:=)|(?:\\\\&:=)|(?:\\\\|\\\\|:=)|(?:<<:=)|(?:>>:=)|(?:!=)|(?:\\\\[)|(?:\\\\])|(?:<)|(?:>)|(?:\\\\[\\\\])'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util\n",
    "\n",
    "def whileFullMatch(reg, line, c, start = 0): #returns last column from line reference and full matched string\n",
    "    col = start+1\n",
    "    #print(len(line))\n",
    "    while(col < len(line) and re.fullmatch(reg,c)):\n",
    "        c += line[col]\n",
    "        col += 1\n",
    "    \n",
    "    if(re.fullmatch(reg, c)):\n",
    "        return col, c\n",
    "    return col-1, c[:-1]\n",
    "    '''\n",
    "    for p in line[col:]:\n",
    "        c+=p\n",
    "        if not re.fullmatch(reg,p):\n",
    "            print(c)\n",
    "            c = c[:-1]\n",
    "            break\n",
    "        col+=1\n",
    "    '''\n",
    "    \n",
    "    return col, c\n",
    "\n",
    "def untilFullMatch(reg, line, c, start = 0): #This function may or may not work well\n",
    "    col = start+1\n",
    "    #print(line)\n",
    "    #print(len(line))\n",
    "    while(col < len(line) and not re.fullmatch(reg,c)):\n",
    "        c += line[col]\n",
    "        col += 1\n",
    "    \n",
    "    if(re.fullmatch(reg, c)):\n",
    "        return col, c\n",
    "    return col-1, c[:-1]\n",
    "\n",
    "def getMore(line, col, n=1):\n",
    "    if col+n > len(line):\n",
    "        return len(line),line[col:]\n",
    "    return col+n, line[col:col+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, '\"N must be a multiple of PR\"')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untilFullMatch(regex['string'], '\"N must be a multiple of PR\"); stop (1) ', '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[\\\\]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '[]'\n",
    "re.escape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.fullmatch(regex['string'], '\"N must be a multiple of PR\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self,row,col,_type = None, lexeme = None):\n",
    "        self.row = row + 1\n",
    "        self.col = col + 1\n",
    "        self.token_type = _type\n",
    "        if lexeme:\n",
    "            self.lexeme = lexeme\n",
    "        else:\n",
    "            self.lexeme = _type\n",
    "        self.error = False\n",
    "        \n",
    "    def parse(self):\n",
    "        if not self.token_type and not self.lexeme:\n",
    "            return '>>> Error lexico(linea:{},posicion:{})'.format(self.row,self.col)\n",
    "        if self.lexeme == self.token_type:\n",
    "            return '<{},{},{}>'.format(self.token_type, self.row, self.col)\n",
    "        return '<{},{},{},{}>'.format(self.token_type, self.lexeme, self.row, self.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.flag = False #Flag for numeric special case\n",
    "        self.error = False\n",
    "        \n",
    "    def readFile(self):\n",
    "        f = open(self.filepath,'r')\n",
    "        self.lines = f.readlines()\n",
    "        f.close()\n",
    "        #reset\n",
    "        self.row = self.col = 0\n",
    "        self.flag = self.error = False\n",
    "    \n",
    "    def cleanLine(self, line):\n",
    "        l = 0\n",
    "        for c in line:\n",
    "            if(c==' '):\n",
    "                self.col+=1\n",
    "            elif(c=='\\t'):\n",
    "                self.col += 3\n",
    "            else:\n",
    "                break\n",
    "            l+=1\n",
    "        return line[l:].strip()\n",
    "    \n",
    "    def number(self, c, line):\n",
    "        # the col we use here is local\n",
    "        # the self.col currently \n",
    "        global regex\n",
    "        reg = regex['numerico']\n",
    "        col, match = whileFullMatch(reg, line, c)\n",
    "\n",
    "        t_col, two_more = getMore(line, col, n = 2)\n",
    "        if re.match(r'[\\.][0-9]', two_more):\n",
    "            match += two_more\n",
    "            col = t_col\n",
    "            col, match = whileFullMatch(reg, line, match, col - 1) # col - 1 because function adds one\n",
    "        \n",
    "        t_col, three_more = getMore(line, col, n = 3)\n",
    "        if re.match(r'[eE][\\+-][0-9]', three_more):\n",
    "            match += three_more\n",
    "            col = t_col\n",
    "            col, match = whileFullMatch(reg, line, match, col - 1) # col - 1 because function adds one\n",
    "        tk = Token(self.row, self.col,'tk_num', match)\n",
    "        self.col += col #increment for the next read\n",
    "        \n",
    "        self.flag = False # Numeric special case\n",
    "        return tk\n",
    "    \n",
    "    def identifier(self, c, line):\n",
    "        global regex, reserved_set\n",
    "        reg = regex['id']\n",
    "        col, match = whileFullMatch(reg, line, c)\n",
    "        #print(col,match)\n",
    "        if match in reserved_set:\n",
    "            tk = Token(self.row, self.col, match)\n",
    "            \n",
    "            #print(tk.token_type, tk.lexeme)\n",
    "            self.col += col #increment for the next read\n",
    "            \n",
    "            self.flag = False # Numeric special case\n",
    "            return tk\n",
    "        \n",
    "        tk = Token(self.row, self.col,'id', match)\n",
    "        self.col += col #increment for the next read\n",
    "        \n",
    "        self.flag = True # numeric special case\n",
    "        return tk\n",
    "    \n",
    "    def tokenMatch(self, c, line):\n",
    "        global token_regex, token_set\n",
    "        \n",
    "        if(not re.match(token_regex, c)):\n",
    "            tk = Token(self.row, self.col) #Error Token\n",
    "            self.error = True\n",
    "            return tk\n",
    "        \n",
    "        col, match = whileFullMatch(token_regex, line, c)\n",
    "        tk = Token(self.row, self.col, token_set[match])\n",
    "        self.col += col #increment for the next read\n",
    "        \n",
    "        self.flag = False # Numeric special case\n",
    "        return tk\n",
    "\n",
    "    def default(self, c, line):\n",
    "        if(re.match(r'[0-9]', c)):\n",
    "            #print('>>>NUM')\n",
    "            return self.number(c, line)\n",
    "        elif(re.match(r'[a-zA-Z_]', c)):\n",
    "            #print('>>>ID')\n",
    "            return self.identifier(c,line)\n",
    "        else:\n",
    "            #print('>>>TOKEN_MATCH')\n",
    "            return self.tokenMatch(c,line)\n",
    "    \n",
    "    def sign(self, c, line):\n",
    "        t_col, one_more = getMore(line, 1)\n",
    "        if re.match(r'[0-9]', one_more):\n",
    "            if not self.flag:\n",
    "                # case, include minus sign within number\n",
    "                self.col +=1\n",
    "                tk = self.number(c+one_more, line[1:])\n",
    "                tk.col-=1\n",
    "                return tk\n",
    "        \n",
    "        self.flag = False # Numeric special case\n",
    "        return self.tokenMatch(c, line)\n",
    "    \n",
    "    def stri(self, c, line): #strings\n",
    "        global regex\n",
    "        reg = regex['string']\n",
    "        col, match = untilFullMatch(reg, line, c)\n",
    "        tk = Token(self.row, self.col, 'tk_cadena', match)\n",
    "        self.col += col\n",
    "        \n",
    "        self.flag = False # Numeric special case\n",
    "        return tk\n",
    "    \n",
    "    def nextToken(self):\n",
    "        if self.error: return ''\n",
    "        flag = True\n",
    "        line = ''\n",
    "        while(line == ''):\n",
    "            if self.row >= len(self.lines): return ''\n",
    "            line = self.lines[self.row][self.col:]\n",
    "            line = self.cleanLine(line)\n",
    "            if line == '' or line[0] == '#': # commentaries handling\n",
    "                self.row += 1\n",
    "                self.col = 0\n",
    "                line = ''\n",
    "        #Process\n",
    "        c = line[0]\n",
    "        opt = {\n",
    "            '+' : self.sign,\n",
    "            '-' : self.sign,\n",
    "            '\"' : self.stri,\n",
    "        }\n",
    "        #print(\">>\",c)\n",
    "        f = opt.get(c, self.default)\n",
    "        #print('-----------')\n",
    "        #print(line)\n",
    "        token = f(c, line)\n",
    "        return token.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'untitled.txt'\n",
    "out_path = 'out.txt'\n",
    "lexer = Lexer(in_file)\n",
    "lexer.readFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(out_path,'w')\n",
    "while (True):\n",
    "    s = lexer.nextToken()\n",
    "    if s=='':\n",
    "        break\n",
    "    #print(s)\n",
    "    f.write(s+'\\n')\n",
    "    steps-=1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff out.txt expected_out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tokens and ids\n",
    "paths = ['out_1.txt', 'out_2.txt', 'out_3.txt']\n",
    "tks = set()\n",
    "ids = set()\n",
    "for p in paths:\n",
    "    p = 'Tests/'+p\n",
    "    f = open(p,'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    for l in lines:\n",
    "        val = re.search('<(.*?),',l).span()\n",
    "        lex = l[val[0]+1:val[1]-1]\n",
    "        if lex[0:2] == 'tk':\n",
    "            tks.add(lex)\n",
    "        else:\n",
    "            ids.add(lex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tk_par_der\n",
      "tk_menos\n",
      "tk_punto_y_coma\n",
      "tk_div\n",
      "tk_mayorque\n",
      "tk_igual\n",
      "tk_num\n",
      "tk_distinto\n",
      "tk_cadena\n",
      "tk_punto\n",
      "tk_multi\n",
      "tk_separa\n",
      "tk_cor_der\n",
      "tk_ejecuta\n",
      "tk_par_izq\n",
      "tk_coma\n",
      "tk_asig\n",
      "tk_menorque\n",
      "tk_dos_puntos\n",
      "tk_cor_izq\n"
     ]
    }
   ],
   "source": [
    "for tk in tks:\n",
    "    print(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global\n",
      "af\n",
      "read\n",
      "if\n",
      "fi\n",
      "resource\n",
      "procedure\n",
      "int\n",
      "getarg\n",
      "cap\n",
      "import\n",
      "id\n",
      "create\n",
      "end\n",
      "stop\n",
      "write\n",
      "send\n",
      "or\n",
      "body\n",
      "fa\n",
      "mod\n",
      "var\n",
      "to\n",
      "returns\n",
      "writes\n"
     ]
    }
   ],
   "source": [
    "for i in ids:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
